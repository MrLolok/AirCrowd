services:
  spark-iceberg:
    image: tabulario/spark-iceberg
    container_name: spark-iceberg
    build: spark/
    networks:
      - aircrowd-network
    depends_on:
      - rest
      - minio
    volumes:
      - warehouse:/home/iceberg/warehouse
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
    ports:
      - ${SPARK_MASTER_PORT}:7077
      - 8888:8888
      - ${SPARK_UI_PORT}:8080
      - 10000:10000
      - 10001:10001

  rest:
    image: tabulario/iceberg-rest
    container_name: iceberg-rest
    networks:
      - aircrowd-network
    ports:
      - ${ICEBERG_REST_PORT}:8181
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000

  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_DOMAIN=${MINIO_DOMAIN}
    networks:
      aircrowd-network:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: [ "server", "/data", "--console-address", ":9001" ]

  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      - aircrowd-network
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

  kafka:
    image: apache/kafka:latest
    hostname: kafka
    container_name: kafka
    networks:
      - aircrowd-network
    ports:
      - ${KAFKA_EXTERNAL_PORT}:9092
      - ${KAFKA_INTERNAL_PORT}:9093
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - ./kafka-init.sh:/usr/bin/kafka-init.sh
    command: [ "sh", "-c", "/usr/bin/kafka-init.sh" ]
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092 || exit 1" ]
      interval: 5s
      timeout: 30s
      retries: 10

  redis:
    image: redis:7-alpine
    container_name: aircrowd-redis
    hostname: aircrowd-redis
    restart: always
    ports:
      - "${REDIS_PORT:-6379}:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
    networks:
      - aircrowd-network
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  discovery-service:
    build:
      context: DiscoveryServer
      dockerfile: Dockerfile
    container_name: aircrowd-discovery-service
    hostname: aircrowd-discovery-service
    restart: always
    ports:
      - "${EUREKA_PORT:-8761}:8761"
    environment:
      - EUREKA_HOSTNAME=aircrowd-discovery-service
      - EUREKA_USERNAME=${EUREKA_USERNAME:-admin}
      - EUREKA_PASSWORD=${EUREKA_PASSWORD:-admin123}
    networks:
      - aircrowd-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8761/actuator/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  weather-service:
    build:
      context: Weather
      dockerfile: Dockerfile
    container_name: aircrowd-weather-service
    hostname: aircrowd-weather-service
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      discovery-service:
        condition: service_healthy
    volumes:
      - aircrowd-weather-service:/home/app/configs
    environment:
      - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://aircrowd-discovery-service:8761/eureka/
      - REDIS_HOST=aircrowd-redis
      - REDIS_PORT=6379
    networks:
      aircrowd-network:

  airport-management-service:
    build:
      context: AirportManagement
      dockerfile: Dockerfile
    container_name: aircrowd-airport-management-service
    hostname: aircrowd-airport-management-service
    restart: always
    ports:
      - "${AIRPORT_MANAGEMENT_PORT:-8080}:8080"
    depends_on:
      redis:
        condition: service_healthy
      discovery-service:
        condition: service_healthy
    environment:
      - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://aircrowd-discovery-service:8761/eureka/
      - REDIS_HOST=aircrowd-redis
      - REDIS_PORT=6379
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      - POSTGRES_DB=${POSTGRES_DB:-aircrowd}
      - POSTGRES_USERNAME=${POSTGRES_USERNAME:-aircrowd}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-aircrowd123}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    networks:
      - aircrowd-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/airport-management/actuator/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  aircrowd-weather-service:
  warehouse:
  redis-data:

networks:
  aircrowd-network:
    name: aircrowd-network
    driver: bridge